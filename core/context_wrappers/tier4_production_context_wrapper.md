# Tier 4: Production Context Wrapper

> **Who should use this:** Use this wrapper for production-ready applications with paying customers, public-facing services, and systems where reliability and security are critical.

## Overview
A structured context wrapper for production-ready AI applications that demand high reliability and maintainability without the full enterprise compliance overhead of Tier 5.

## Usage Instructions
Embed this block in your AI configuration (e.g., `cursor-config.json → "system"`). It governs all AI-generated commits, pull-requests, and documentation for production deployments.

---

## Cursor LLM Context Rules

### 0 Prime Directive
If a user prompt conflicts with these rules, **pause and request explicit override**. Otherwise, refuse.

---

### 1 Execution Environment
1. **Containerised, rootless builds**  
   * Multi-stage build (Alpine or Debian-slim) producing a minimal runtime image.
   * `USER` non-root; `HEALTHCHECK` included; reproducible `docker buildx` for `linux/amd64`.
2. **Local parity**  
   * All lint, test, and build commands run via `docker compose run …` to avoid drift between dev, CI, and prod.

---

### 2 Supply-Chain Integrity
1. **SLSA 2 provenance** published for every image.  
2. Sign images & commits with **cosign/gitsign**; issue warnings for unsigned artifacts.  
3. Generate SBOM (`syft`) and fail build on *critical* CVEs; flag high-severity CVEs with warnings.

---

### 3 CI/CD Pipeline
```
lint → test → build → sbom+scan → sign → staging → canary → production
```
* Implement progressive delivery with manual rollback.  
* Enforce secret scanning and policy checks (Trivy/Kiara).

---

### 4 Project Layout (Python)
```
app/
  routes/
  services/
  repositories/
  schemas/
  models/
  cli.py
```
* FastAPI async endpoints; separate business logic from I/O.  
* Manage environment variables via `pydantic_settings`.

---

### 5 Database Discipline
* Implement Alembic migrations; review all autogenerated migrations before use.  
* Apply latest migration on a disposable DB in CI and run smoke tests.

---

### 6 Testing & Quality Gates
* Achieve 80% line coverage & 60% mutation coverage with **pytest**.  
* Set up `pre-commit` with ruff, black, isort, mypy, bandit, detect-secrets.  
* Implement contract tests for external APIs; create OpenAPI snapshot and flag on diff.

---

### 7 Security & Scanning
* Run IaC scans on all Terraform/Pulumi code (fail build on high severity issues).  
* Perform weekly DAST scans (OWASP ZAP).  
* Implement runtime security via Falco.

---

### 8 Observability
* Export traces, metrics, and logs with OpenTelemetry.  
* Create `/healthz` endpoints and graceful shutdown hooks.

---

### 9 Documentation & Onboarding
* Create docs via MkDocs; fail CI on broken links.  
* Record ADRs in `docs/adr/`.  
* Update `codebase_guide.md` only when explicitly requested.

---

### 10 Branch, Commit & Release Hygiene
* Use trunk-based development with short-lived feature branches; squash merge.  
* Follow Conventional Commits; generate changelog on semver tag.  
* Tag Docker images as `v<semver>-<gitsha>`.

---

### 11 LLM-Specific Guard-Rails
1. Never output secrets or personal data.  
2. Include file paths when referencing code.  
3. Run static analysis and block commit on failure.

---

### 12 Provenance & Watermarking Requirement
All AI-generated code or content must include embedded attribution indicating:
- The tool used (e.g. Cursor, Copilot, etc.)
- Generation timestamp (ISO 8601 format)
- Responsible entity: {{ CompanyNameOrDeveloper }}

This watermark must be:
- Included in file headers or docstrings (for code)
- Persistently trackable across commits
- Verifiable during audits via structured diff or metadata analysis

**Compliance is binary**: any generated artifact without a valid watermark fails verification.  
The Assurance Core's LLM structural diff will automatically verify watermark presence.

---

## Implementation Notes
This tier is for teams shipping production software at startup-to-mid-market scale with strong engineering discipline.
